\chapter{Introduction}\label{s:introduction}

Large software systems are a composition of intertwined units of functionality,
often related in complex ways. They can be developed across many years and by 
large teams. It is no surprise that complexity arises quite easily. 

It becomes progressively harder to add new features and improvements while being 
sure that everything else works as it should. That is, the software remains
correct. To tackle this problem of complexity, many strategies and different 
angles have been studied and implemented by large-scale software systems. 

Automated regression testing \cite{baresiregtest} is one of the main strategies widely adopted by the industry \cite{10.1007/s10606-009-9098-7},
to ensure that changes to the code will not negatively affect the users of the system. 
This technique consists of developers writing automated tests: code that executes scenarios that a user would experience
and asserts that the desired properties hold. Afterwards, when changes to the code are done,
executing successfully the set of automated tests gives confidence that such scenarios will
not be impacted by the change. In practice, this is an effective technique to preserve the quality of the system while
evolving. \cite{10.1007/s10606-009-9098-7}\cite{baresiregtest}

Another challenge in software engineering consists in having an effective development process when
working with large teams. One of the solutions widely adopted by the industry is to use \emph{Continuous Integration} (CI) processes.

The main idea of the CI software development process is that developers should 
integrate code changes frequently. When developers integrate their changes, 
they make other developers on the team aware of these changes. If the changes
 conflict with their work, they can react accordingly.

Frequently integrating changes to the product increases the risk of making mistakes.
For that reason, as a safeguard, the set of automated tests should be run before 
integrating every change. The process of building and testing the code automatically
every time a change is meant to be integrated is called a CI pipeline and it is typically
enforced in the development processes of industrial software products.

By frequently integrating changes with the regression test suite backing its correctness
we ensure quality in every small step.

However, there is a drawback: as the system evolves, more regression tests
get added, and eventually, it can become time-consuming to run the complete
set of automated tests. Even more, if this is done every time a developer wishes to
integrate changes to the codebase, which is the case in the context of CI.

To address this problem, academic research and industry have focused on several angles.
Algorithms on Test Selection and Prioritization (TSP) are techniques that aim to 
automatically propose a relevant sorted subset of tests to execute. The rationale
behind these techniques is that since the goal of executing the test suite is to
find failing test cases for the given change, we can avoid executing unrelated tests
by selecting a subset of them and executing first the ones that are more likely to fail.

Not only is optimizing CI pipelines relevant for improving the agility of software development, 
but it also has a positive impact on the energy resources they require.
These pipelines are run multiple times a day, and the cost of operating the infrastructure
required to keep the system evolving is significant.

For this project, TSP techniques are applied and evaluated for data collected from one of the CI pipelines
of the \emph{Business Central} project. \emph{Business Central} is an Enterprise Resource Planning (ERP)
software product by Microsoft.  The aim is to find a suitable technique for this pipeline and to 
propose possible directions to improve the CI cycle feedback time and effectiveness.

The techniques explored are based upon previous work by Bertolino
et. al. in \cite{Bertolino2020LearningtoRankVR}, where the prioritization problem is transformed
into a \emph{ranking} problem. We then apply different \emph{Learning to Rank} algorithms and evaluate
their results. However, in contrast to their approach, we propose the usage of coverage information 
as a criterion for these techniques.

For clarity, we will focus on the following research questions:
\begin{itemize}
    \item \textbf{RQ1}: Which of the ranking techniques yields the best prioritization results?
    \item \textbf{RQ2}: To what extent the number of tests and their execution time can be reduced?
    \item \textbf{RQ3}: What is the effect of using coverage information for \emph{Learning to Rank} techniques?
\end{itemize}

Throughout this work, we also outline the different challenges and technical difficulties that adapting
academic techniques posed when taking into consideration the practical realities
of an industrial environment. Additionally, we discuss how these techniques could
be used in the existing context of the pipeline.

All the code for the different stages of the project can be found 
in the accompanying repository.\footnote{\url{https://github.com/mynjj/msc-thesis-public}}